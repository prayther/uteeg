---
- name: oVirt ocp vm node build playbook
  hosts: localhost
  connection: local
  gather_facts: false
  vars_files:
    - vars_files/password.yml
  pre_tasks:
    - name: Login to oVirt
      ovirt_auth:
        hostname: "{{ engine_fqdn }}"
        username: "{{ engine_user }}"
        password: "{{ engine_password }}"
        ca_file: "{{ engine_cafile }}"
        insecure: "{{ engine_insecure | default(true) }}"
      tags:
        - always
  vars:
    engine_fqdn: virt1.example.org
    engine_user: admin@internal
    engine_cafile: /etc/ansible/ca.pem
    #vm_datacenter: Default
    vm_cluster: Default
    vm_template: default
    vm_storage_domain: hosted_storage
    vm_domain: ocp.example.org
    qcow_path: files/rhel-server-7.7-x86_64-kvm.qcow2
    #ssh_public_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQD6bwWbzdzwx33QMR5FwUosXraOchkS5Ci7wj5s1taW62vzrlxXQF1RzxAegCTaJKy4sKcoMgNmx77TsXkaqA/vfzkgW//EStMr/q/QGzMePS/uYaUyGf0XvmUnouEKgUQhRq8q0G4Wa9uOmsiQDJEgIexyXZa8HSRo2dWyJd4A0UcJklR4yvTMuNd8Uq1qAVuMzBhy1075DMNRi56RW5bRs2N2nhiFuesC6RF3RDJKkRO6ld3e+0ddqFWhMIYyB9VpifH6UnSBUUmu3yW8uqFJ3Pnh908lWYqqADNj5zBezTi+mJqdKhZF77RaDhaBLG1i+llf0NBqHBWiihoeKbFP root@fedora-26.prayther.org

    common:
        vm_user_root: root
        vm_user_root_passwd: password
    network:
        vm_netmask: 255.255.255.0
        vm_gateway: 192.168.1.1
        vm_dns_server: 192.168.1.120

  tasks:
  - name: Create VM with cloud init
    ovirt_vm:
      auth: "{{ ovirt_auth }}"
      name: "{{ item.name }}"
      template: "{{ vm_template }}"
      cluster: "{{ vm_cluster }}"
      memory: "{{ item.vm_memory }}"
      cpu_sockets: "{{ item.vm_cpu_sockets }}"
      state: present
      high_availability: true
      high_availability_priority: 50  # Available from Ansible 2.5
      cloud_init:
        # workaround for 192.168.122.1 being erroringly in the rhel qcow2 image
        custom_script: |
          write_files:
           - content: |
               nameserver 192.168.1.120
               nameserver 192.168.1.100
             path: /etc/resolv.conf
             permissions: '0644'
        host_name: "{{ item.host_name }}"
        nic_boot_protocol: static
        nic_ip_address: "{{ item.nic_ip_address }}"
        nic_netmask: "{{ network.vm_netmask }}"
        nic_gateway: "{{ network.vm_gateway }}"
        dns_servers: "{{ network.vm_dns_server }}"
        nic_name: eth0
        nic_on_boot: true
        user_name: "{{ common.vm_user_root }}"
        root_password: "{{ common.vm_user_root_passwd }}"
        authorized_ssh_keys: "{{ vault_ssh_public_key }}"
      cloud_init_persist: true
    loop:
      - { name: 'master0', vm_memory: '16GiB', vm_cpu_sockets: '4', host_name: 'master0.ocp.example.org', nic_ip_address: '192.168.1.18' }
      - { name: 'master1', vm_memory: '16GiB', vm_cpu_sockets: '4', host_name: 'master1.ocp.example.org', nic_ip_address: '192.168.1.16' }
      - { name: 'master2', vm_memory: '16GiB', vm_cpu_sockets: '4', host_name: 'master2.ocp.example.org', nic_ip_address: '192.168.1.17' }
      - { name: 'infra0', vm_memory: '8GiB', vm_cpu_sockets: '1', host_name: 'infra0.ocp.example.org', nic_ip_address: '192.168.1.24' }
      - { name: 'infra1', vm_memory: '8GiB', vm_cpu_sockets: '1', host_name: 'infra1.ocp.example.org', nic_ip_address: '192.168.1.22' }
      - { name: 'infra2', vm_memory: '8GiB', vm_cpu_sockets: '1', host_name: 'infra2.ocp.example.org', nic_ip_address: '192.168.1.23' }
      - { name: 'compute0', vm_memory: '8GiB', vm_cpu_sockets: '1', host_name: 'compute0.ocp.example.org', nic_ip_address: '192.168.1.21' }
      - { name: 'lb0', vm_memory: '4GiB', vm_cpu_sockets: '1', host_name: 'lb0.ocp.example.org', nic_ip_address: '192.168.1.25' }

    # Upload local image to disk and attach it to vm:
    # Since Ansible 2.3
  - name: Add RHEL qcow2 disc
    ovirt_disk:
      auth: "{{ ovirt_auth }}"
      name: disc1
      force: true
      sparse: true
      vm_name: "{{ item }}"
      interface: virtio
      size: 10GiB
      format: cow
      image_path: "{{ qcow_path }}"
      storage_domain: "{{ vm_storage_domain }}"
    loop:
      - master0
      - master1
      - master2
      - infra0
      - infra1
      - infra2
      - compute0
      - lb0

  - name: Increase the size of the RHEL OS disc
    ovirt_disk:
      auth: "{{ ovirt_auth }}"
      name: disc1
      #force: true
      vm_name: "{{ item.name }}"
      interface: virtio
      size: "{{ item.vm_disc_vda }}"
      state: attached
      #format: cow
      #storage_domain: "{{ vm_storage_domain }}"
    loop:
      - { name: 'master0', vm_disc_vda: '50GiB' }
      - { name: 'master1', vm_disc_vda: '50GiB' }
      - { name: 'master2', vm_disc_vda: '50GiB' }
      - { name: 'infra0', vm_disc_vda: '50GiB' }
      - { name: 'infra1', vm_disc_vda: '50GiB' }
      - { name: 'infra2', vm_disc_vda: '50GiB' }
      - { name: 'compute0', vm_disc_vda: '50GiB' }
      - { name: 'lb0', vm_disc_vda: '50GiB' }

  - name: Add disc for data
    ovirt_disk:
      auth: "{{ ovirt_auth }}"
      name: disc2
      force: true
      sparse: true
      vm_name: "{{ item.name }}"
      interface: virtio
      size: "{{ item.vm_disc_vdb }}"
      format: cow
      storage_domain: hosted_storage
    loop:
      - { name: 'master0', vm_disc_vdb: '50GiB' }
      - { name: 'master1', vm_disc_vdb: '50GiB' }
      - { name: 'master2', vm_disc_vdb: '50GiB' }
      - { name: 'infra0', vm_disc_vdb: '50GiB' }
      - { name: 'infra1', vm_disc_vdb: '50GiB' }
      - { name: 'infra2', vm_disc_vdb: '50GiB' }
      - { name: 'compute0', vm_disc_vdb: '50GiB' }
      - { name: 'lb0', vm_disc_vdb: '50GiB' }

  - name: Set state running
    ovirt_vm:
      auth: "{{ ovirt_auth }}"
      state: running
      name: "{{ item }}"
    loop:
      - master0
      - master1
      - master2
      - infra0
      - infra1
      - infra2
      - compute0
      - lb0

  - name: Wait for port 22 to be open. That means the vm is up.
    wait_for:
      host: "{{ item }}"
      port: 22
      search_regex: OpenSSH
      delay: 10
    loop:
      - master0
      - master1
      - master2
      - infra0
      - infra1
      - infra2
      - compute0
      - lb0

  post_tasks:
    - name: Logout from oVirt
      ovirt_auth:
        state: absent
        ovirt_auth: "{{ ovirt_auth }}"
      tags:
        - always
